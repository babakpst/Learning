{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZomkmp8wp4b"
   },
   "source": [
    "Below two lines install and load the extension to run CUDA code in Jupyter cells. Also, we need to make sure that GPU (T4) is selected as the hardware accelerator in Runtime -> Change runtime type.\n",
    "\n",
    "For details please see: https://medium.com/@iphoenix179/running-cuda-c-c-in-jupyter-or-how-to-run-nvcc-in-google-colab-663d33f53772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEIba1yZtjhs"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zezEUcP-Laza"
   },
   "source": [
    "You can check the GPU type  assigned to you by running nvidia-smi. Please specify the GPU type used for the performance measurements in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hv3Q6oYPLdi5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CXStwc5x-iM"
   },
   "source": [
    "The assignment code is below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-xxSM6Mrdot"
   },
   "outputs": [],
   "source": [
    "%%cu\n",
    "\n",
    "/*\n",
    "Babak Poursartip\n",
    "12/16/2023\n",
    "\n",
    "Run commands: \n",
    "sudo nvprof --metrics gld_efficiency,gst_efficiency,branch_efficiency,sm_efficiency,achieved_occupancy,warp_execution_efficiency,inst_per_warp,stall_sync,dram_utilization ./bin/main\n",
    "\n",
    "Assumptions:\n",
    "- I assumed the matrix size is fixed and dimensions are multiples of 1024. n iteration is multiple of 5. \n",
    "- I assuming dimx, dimy are multiples of block.x, block.y\n",
    "\n",
    "global load/store efficiency: 100\n",
    "I attached the report from nvprof and nvvp.\n",
    "\n",
    "On my GPU (NVIDIA GeForce GT 1030 - 3 SM) the original code takes ~850 milli seconds and my code \n",
    "takes ~22 milli seconds (38x).\n",
    "\n",
    "*/\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <limits.h>\n",
    "\n",
    "bool checkResults (float *gold, float *d_data, int dimx, int dimy, float rel_tol) {\n",
    "  for (int iy = 0; iy < dimy; ++iy) {\n",
    "    for (int ix = 0; ix < dimx; ++ix) {\n",
    "      int idx = iy * dimx + ix;\n",
    "\n",
    "      float gdata = gold[idx];\n",
    "      float ddata = d_data[idx];\n",
    "\n",
    "      if (isnan(gdata) || isnan(ddata)) {\n",
    "        printf(\"Nan detected: gold %f, device %f\\n\", gdata, ddata);\n",
    "        return false;\n",
    "      }\n",
    "\n",
    "      float rdiff;\n",
    "      if (fabs(gdata) == 0.f)\n",
    "        rdiff = fabs(ddata);\n",
    "      else\n",
    "        rdiff = fabs(gdata - ddata) / fabs(gdata);\n",
    "\n",
    "      if (rdiff > rel_tol) {\n",
    "        printf(\"Error solutions don't match at iy=%d, ix=%d.\\n\", iy, ix);\n",
    "        printf(\"gold: %f, device: %f\\n\", gdata, ddata);\n",
    "        printf(\"rdiff: %f\\n\", rdiff);\n",
    "        return false;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return true;\n",
    "}\n",
    "\n",
    "void computeCpuResults(float *g_data, int dimx, int dimy, int niterations,\n",
    "                       int nreps) {\n",
    "  for (int r = 0; r < nreps; r++) {\n",
    "    printf(\"Rep: %d\\n\", r);\n",
    "#pragma omp parallel for\n",
    "    for (int iy = 0; iy < dimy; ++iy) {\n",
    "      for (int ix = 0; ix < dimx; ++ix) {\n",
    "        int idx = iy * dimx + ix;\n",
    "\n",
    "        float value = g_data[idx];\n",
    "\n",
    "        for (int i = 0; i < niterations; i++) {\n",
    "          if (ix % 4 == 0) {\n",
    "            value += sqrtf(logf(value) + 1.f);\n",
    "          } else if (ix % 4 == 1) {\n",
    "            value += sqrtf(cosf(value) + 1.f);\n",
    "          } else if (ix % 4 == 2) {\n",
    "            value += sqrtf(sinf(value) + 1.f);\n",
    "          } else if (ix % 4 == 3) {\n",
    "            value += sqrtf(tanf(value) + 1.f);\n",
    "          }\n",
    "        }\n",
    "        g_data[idx] = value;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "__global__ void kernel_A(float *g_data, int dimx, int niterations) \n",
    "{\n",
    "  // create a 2D thread block: each thread computes one element of g_data\n",
    "  int ix = blockIdx.x * blockDim.x + threadIdx.x; // thread id in x direction in the global grid\n",
    "  int iy = blockIdx.y * blockDim.y + threadIdx.y; // thread id in y direction in the global \n",
    "  int idx = iy * dimx + ix; // global index in g_data\n",
    "  \n",
    "  int sidx = threadIdx.y * blockDim.x + threadIdx.x; // shared index in the block for s_data\n",
    "  \n",
    "  // Create a shared memory array: fetch data from global memory (g_data) to shared memory (s_data).\n",
    "  // Why do we need this? \n",
    "  //  - Every four columns of the matrix has a different operation. \n",
    "  //  - CUDA assigns thread IDs in a thread block to warps, in a way that x varies faster than y than z.\n",
    "  //  - The original implementation, results in a 4-way thread divergence. \n",
    "  //  - To avoid divergence, we copy the data from global memory to shared memory. The shared memory is needed \n",
    "  //    because threads access the data in un-coalesced manner (uncoalesed access in global memory is expensive).\n",
    "  extern __shared__ float s_data[];\n",
    "  \n",
    "  // copy data from global memory (aligned+coalesced) to shared memory (aligned+coalesced)\n",
    "  s_data[sidx] = g_data[idx];\n",
    "  \n",
    "  // Barrier/Wait for all threads to finish copying data to shared memory.\n",
    "  // This is needed because we don't want to start computation before threads finish store in the shared memory. \n",
    "  // Each thread will work on a different element of the shared memory.\n",
    "  __syncthreads(); \n",
    "  \n",
    "  // index of the element in the shared memory that the thread is working on.\n",
    "  // reading in col-major order to avoid thread divergence.\n",
    "  int col_idx = threadIdx.x * blockDim.y + threadIdx.y;\n",
    "  float value = s_data[col_idx];\n",
    "  \n",
    "  int tidy = threadIdx.y;\n",
    "  \n",
    "  // Uncomment the following for loop if niterations is greater than 5 and a multiple of 5.\n",
    "  // for (int i = 0; i < niterations/5; i++) \n",
    "  // {\n",
    "  // To have the same computation as the original code, we need to have the branch condition. There is no divergence here.\n",
    "  // use CUDA/intrinsic functions, faster but less accurate. The results are withing the tolerance.\n",
    "    if (tidy % 4 == 0) {\n",
    "      value += __fsqrt_rn(__logf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__logf(value) + 1.f); // 5-fold loop unrolling\n",
    "      value += __fsqrt_rn(__logf(value) + 1.f); // 5-fold loop unrolling\n",
    "      value += __fsqrt_rn(__logf(value) + 1.f); // 5-fold loop unrolling\n",
    "      value += __fsqrt_rn(__logf(value) + 1.f); // 5-fold loop unrolling\n",
    "    } else if (tidy % 4 == 1) {\n",
    "      value += __fsqrt_rn(__cosf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__cosf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__cosf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__cosf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__cosf(value) + 1.f);\n",
    "    } else if (tidy % 4 == 2) {\n",
    "      value += __fsqrt_rn(__sinf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__sinf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__sinf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__sinf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__sinf(value) + 1.f);\n",
    "    } else if (tidy % 4 == 3) {\n",
    "      value += __fsqrt_rn(__tanf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__tanf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__tanf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__tanf(value) + 1.f);\n",
    "      value += __fsqrt_rn(__tanf(value) + 1.f);\n",
    "    }\n",
    "  // }\n",
    "\n",
    "  // uncomment the following for loop if niterations is not a multiple of 5.\n",
    "  // for (int i = 0; i < niterations%5; i++) \n",
    "  // {  \n",
    "  //   if (iy % 4 == 0) {\n",
    "  //     value += __fsqrt_rn(__logf(value) + 1.f);\n",
    "  //   } else if (iy % 4 == 1) {\n",
    "  //     value += __fsqrt_rn(__cosf(value) + 1.f);\n",
    "  //   } else if (iy % 4 == 2) {\n",
    "  //     value += __fsqrt_rn(__sinf(value) + 1.f);\n",
    "  //   } else if (iy % 4 == 3) {\n",
    "  //     value += __fsqrt_rn(__tanf(value) + 1.f);\n",
    "  //   }\n",
    "  // }\n",
    "      \n",
    "  \n",
    "  // store the result in the shared memory\n",
    "  s_data[col_idx] = value;\n",
    "  \n",
    "  // Wait until all threads finish copying data to shared memory. \n",
    "  // Each thread will work on a different element of the shared memory when storing to the global memory.\n",
    "  __syncthreads();\n",
    "\n",
    "  // global store, aligned+coalesced\n",
    "  g_data[idx] = s_data[sidx];\n",
    "}\n",
    "\n",
    "void launchKernel(float * d_data, int dimx, int dimy, int niterations) {\n",
    "  // Only change the contents of this function and the kernel(s). You may\n",
    "  // change the kernel's function signature as you see fit. \n",
    "\n",
    "  // assuming dimx, dimy are multiples of 1024\n",
    "  // reducing the number of threads per block, reduces the wait time at syncthreads.\n",
    "\n",
    "  // dim3 block(16, 16);\n",
    "  // dim3 block(1, 1024);\n",
    "  // dim3 block(1024, 1);\n",
    "  // dim3 block(32, 32);\n",
    "  // dim3 block(32, 16);\n",
    "  // dim3 block(32, 8);\n",
    "\n",
    "\n",
    "  // dim3 block(64, 4);\n",
    "  // dim3 block(32, 8);\n",
    "  dim3 block(32, 4);\n",
    "  // dim3 block(32, 1); \n",
    "  dim3 grid(dimx/block.x, dimy/block.y);\n",
    "\n",
    "  \n",
    "// bbk: 64 bit cash line size, we need 2 floats to shift data to the next bank. \n",
    "\n",
    "  // kernel_A<<<grid, block,  (block.x)   * block.y * sizeof(float)>>>(d_data, dimx, niterations);\n",
    "  // padding the shared memory to avoid bank conflicts (but I see no difference in the performance).\n",
    "  kernel_A<<<grid, block,  (block.x+2)   * block.y * sizeof(float)>>>(d_data, dimx, niterations);\n",
    "}\n",
    "\n",
    "float timing_experiment(float *d_data,\n",
    "  int dimx, int dimy, int niterations, int nreps) {\n",
    "  float elapsed_time_ms = 0.0f;\n",
    "  cudaEvent_t start, stop;\n",
    "  cudaEventCreate(&start);\n",
    "  cudaEventCreate(&stop);\n",
    "\n",
    "  cudaEventRecord(start, 0);\n",
    "  for (int i = 0; i < nreps; i++) {\n",
    "    launchKernel(d_data, dimx, dimy, niterations);\n",
    "  }\n",
    "  cudaEventRecord(stop, 0);\n",
    "  cudaDeviceSynchronize();\n",
    "  cudaEventElapsedTime(&elapsed_time_ms, start, stop);\n",
    "  elapsed_time_ms /= nreps;\n",
    "\n",
    "  cudaEventDestroy(start);\n",
    "  cudaEventDestroy(stop);\n",
    "\n",
    "  return elapsed_time_ms;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "  int dimx = 8 * 1024;\n",
    "  int dimy = 8 * 1024;\n",
    "\n",
    "  int nreps = 10;\n",
    "  int niterations = 5;\n",
    "\n",
    "  int nbytes = dimx * dimy * sizeof(float);\n",
    "\n",
    "  float *d_data = 0, *h_data = 0, *h_gold = 0;\n",
    "  cudaMalloc((void **)&d_data, nbytes);\n",
    "  if (0 == d_data) {\n",
    "    printf(\"couldn't allocate GPU memory\\n\");\n",
    "    return -1;\n",
    "  }\n",
    "  printf(\"allocated %.2f MB on GPU\\n\", nbytes / (1024.f * 1024.f));\n",
    "  h_data = (float *)malloc(nbytes);\n",
    "  h_gold = (float *)malloc(nbytes);\n",
    "  if (0 == h_data || 0 == h_gold) {\n",
    "    printf(\"couldn't allocate CPU memory\\n\");\n",
    "    return -2;\n",
    "  }\n",
    "  printf(\"allocated %.2f MB on CPU\\n\", 2.0f * nbytes / (1024.f * 1024.f));\n",
    "  for (int i = 0; i < dimx * dimy; i++) h_gold[i] = 1.0f + 0.01*(float)rand()/(float)RAND_MAX;\n",
    "  cudaMemcpy(d_data, h_gold, nbytes, cudaMemcpyHostToDevice);\n",
    "\n",
    "  timing_experiment(d_data, dimx, dimy, niterations, 1);\n",
    "  printf(\"Verifying solution\\n\");\n",
    "\n",
    "  cudaMemcpy(h_data, d_data, nbytes, cudaMemcpyDeviceToHost);\n",
    "\n",
    "  float rel_tol = .001;\n",
    "  computeCpuResults(h_gold, dimx, dimy, niterations, 1);\n",
    "  bool pass = checkResults(h_gold, h_data, dimx, dimy, rel_tol);\n",
    "\n",
    "  if (pass) {\n",
    "    printf(\"Results are correct\\n\");\n",
    "  } else {\n",
    "    printf(\"FAIL:  results are incorrect\\n\");\n",
    "  }  \n",
    "\n",
    "  float elapsed_time_ms = 0.0f;\n",
    " \n",
    "  elapsed_time_ms = timing_experiment(d_data, dimx, dimy, niterations,\n",
    "                                      nreps);\n",
    "  printf(\"A:  %8.2f ms\\n\", elapsed_time_ms);\n",
    "\n",
    "  printf(\"CUDA: %s\\n\", cudaGetErrorString(cudaGetLastError()));\n",
    "\n",
    "  if (d_data) cudaFree(d_data);\n",
    "  if (h_data) free(h_data);\n",
    "\n",
    "  cudaDeviceReset();\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
